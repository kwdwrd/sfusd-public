{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e26b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f742f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Data exploration\n",
    "# > Still need to include data on TK auto-promotions\n",
    "# > Need to include data from missing years\n",
    "#\n",
    "data_directory = '../cleaned/'\n",
    "file_columns = dict()\n",
    "\n",
    "for filename in os.listdir(data_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_columns[filename] = pd.read_csv(os.path.join(data_directory, filename)).columns.tolist()\n",
    "\n",
    "for filename, columns in file_columns.items():\n",
    "    print(f\"{filename}: {columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cd363fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_descriptions = [\n",
    "    ( '25-26', '3. March 2025 SFUSD Requests by School.csv', 'idSchool', 'SchoolName', 'Program code', 'Program Name', 'Grade' ),\n",
    "    ( '24-25', '3. March 2024 SFUSD Requests by school.xlsx - Table 1.csv', 'idSchool', 'SchoolName', 'Program Code', 'Program Name', 'Grade' ),\n",
    "    ( '23-24', '2023-24 Main Round Requests by School-Grade-Program_1.xlsx - Table 1.csv', 'School ID', 'School Name', 'Program', 'Program Name', 'Grade' ),\n",
    "    ( '22-23', 'Requests by School, Grade, Program.xlsx - 2022-23 - Table 1.csv', 'School ID', 'School Name', 'Program Code', 'Program Name', 'Grade' ),\n",
    "    ( '21-22', 'Enrollment Highlights 2021-22 MR - Program by Rank.xlsx - Table 1.csv', None, 'SchoolName', None, 'Program', 'Grade' ),\n",
    "    # ( '20-21', '...', None, 'School', None, 'Program', 'Grade' ),\n",
    "    ( '19-20', 'sfusd_program_requests_by_rank_2019_2020_parsed.csv', None, 'School', None, 'Program', 'Grade' ),\n",
    "    #( '18-19', 'sfusd_lottery_2018_2019_parsed.csv', 'idSchool', 'SchoolName', None, 'Program', 'Grade' ), # this year is broken\n",
    "    ( '17-18', 'sfusd_lottery_2017_2018_parsed.csv', 'SchoolCode', 'School', None, 'Prg', 'Grade'),\n",
    "    ( '16-17', 'sfusd_lottery_2016_2017_parsed.csv', 'SchoolCode', 'School', None, 'Prg', 'Grade'),\n",
    "    ( '15-16', 'sfusd_lottery_2015_2016_parsed.csv', 'SchoolCode', 'School', None, 'Prg', 'Grade'),\n",
    "    ( '14-15', 'sfusd_lottery_2014_2015_parsed.csv', 'SchoolCode', 'School', None, 'Prg', 'Grade'),\n",
    "    ( '13-14', 'sfusd_lottery_2013_2014_parsed.csv', 'SchoolCode', 'School', None, 'Prg', 'Grade'),\n",
    "    ( '12-13', 'sfusd_lottery_2012_2013_parsed.csv', 'SchoolCode', 'School', None, 'Prg', 'Grade')\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Check for errors\n",
    "#\n",
    "file_content_errors = []\n",
    "\n",
    "for ay, filename, school_id_column, school_name_column, program_code_column, program_name_column, grade_column in file_descriptions:\n",
    "    df = pd.read_csv( f'{data_directory}/{filename}' )\n",
    "\n",
    "    for column in [ school_id_column, school_name_column, program_code_column, program_name_column, grade_column ]:\n",
    "        if column is None:\n",
    "            continue\n",
    "\n",
    "        if column not in df:\n",
    "            file_content_errors.append( ( ay, filename, column ) )\n",
    "            print( f'Missing column \"{column}\" in {filename} for {ay}' )\n",
    "            print( f'Columns found: {df.columns.tolist()}' )\n",
    "\n",
    "if len( file_content_errors ) > 0:\n",
    "    raise Exception( f'Found the following file content errors: {file_content_errors}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "4ef762e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Parse the files\n",
    "#\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "def to_bounds ( choice_range ):\n",
    "    parsed_col = re.sub( r'[^\\d\\-\\+]', '', choice_range )\n",
    "    parts = re.split( r'\\-', parsed_col )\n",
    "    if len( parts ) > 1:\n",
    "        return ( int( parts[0] ), int( parts[1] ) )\n",
    "    elif parts[0][-1] == '+':\n",
    "        return ( int( parts[0][:-1] ), np.inf )\n",
    "    else:\n",
    "        return ( int( parts[0] ), int( parts[0] ) )\n",
    "\n",
    "for ay, filename, school_id_column, school_name_column, program_code_column, program_name_column, grade_column in file_descriptions:\n",
    "    df = pd.read_csv( f'{data_directory}/{filename}' )\n",
    "\n",
    "    choice_columns = [ col for col in df.columns if re.search( r'(?:[Cc]hoice|\\+|^\\d+)', col ) ]\n",
    "    choice_columns = { col: to_bounds( col ) for col in choice_columns }\n",
    "\n",
    "    for choice_column, bounds in choice_columns.items():\n",
    "        choice_min, choice_max = bounds\n",
    "        select_columns = [ school_id_column, school_name_column, program_code_column, program_name_column, grade_column, choice_column ]\n",
    "        select_columns = [ col for col in select_columns if col is not None ]\n",
    "        subdf = df \\\n",
    "            [select_columns] \\\n",
    "            .rename( columns = {\n",
    "                school_id_column: 'school_id',\n",
    "                school_name_column: 'school_name',\n",
    "                program_code_column: 'program_code',\n",
    "                program_name_column: 'program_name',\n",
    "                grade_column: 'grade',\n",
    "                choice_column: 'num_requests'\n",
    "            } ) \\\n",
    "            .assign(\n",
    "                choice_min = choice_min,\n",
    "                choice_max = choice_max,\n",
    "                ay = ay\n",
    "            )\n",
    "        \n",
    "        full_df = pd.concat( [ full_df, subdf ], ignore_index = True, axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f7fa7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Do some cleaning\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "68a1c759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['13', 'TK', 'K', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
       "       '11', '12', 'PK'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Clean grades\n",
    "# > Note that the \"555\" may indicate data issues\n",
    "# > Do we need to do anything about PK or 13?\n",
    "#\n",
    "full_df = full_df.assign( grade = full_df.grade.str.upper() )\n",
    "full_df = full_df[~full_df.grade.isin( [ '555', 'TOTAL' ] )]\n",
    "full_df = full_df.assign( grade = full_df.grade.fillna( '' ).apply( lambda x: re.sub( r'(?:^0|TH GRADE)', '', x ) ) )\n",
    "full_df = full_df[full_df.grade != ''] # removes Miraloma Newcomer 2019-2020\n",
    "\n",
    "display( full_df.grade.unique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "023e78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Massage the school IDs\n",
    "# > Note that there are some inconsistencies in the treatment of ES-associated TK programs\n",
    "#\n",
    "modes = [ 'export', 'search', 'import' ]\n",
    "mode_school_update = 'import'\n",
    "\n",
    "export_filename = './schools.csv'\n",
    "import_filename = './schools.csv'\n",
    "\n",
    "search_school_contains = 'Academy'\n",
    "search_school_grades = [ '9' ]\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Don't mess with the below\n",
    "#\n",
    "if mode_school_update == 'export':\n",
    "    df = full_df[['school_id','school_name']].drop_duplicates()\n",
    "    df = df.merge( df[~pd.isnull( df.school_id )], on = 'school_name', suffixes = ( '_left', '_right' ), how = 'left' ).drop_duplicates()\n",
    "\n",
    "    num_missing_ids = len( df[pd.isnull( df.school_id_right )] )\n",
    "    print( f'Found {num_missing_ids} school[s] without IDs.' )\n",
    "\n",
    "    if num_missing_ids > 0:\n",
    "        df.to_csv( export_filename, index = False )\n",
    "\n",
    "    raise Exception( 'Cannont continue until \"import\" flag is set.' )\n",
    "\n",
    "\n",
    "\n",
    "if mode_school_update == 'search':\n",
    "    df = full_df\n",
    "\n",
    "    if search_school_contains is not None:\n",
    "        df = df[df.school_name.str.contains( search_school_contains )]\n",
    "    if search_school_grades is not None:\n",
    "        df = df[df.grade.isin( search_school_grades )]\n",
    "\n",
    "    df = df \\\n",
    "        [['school_name','school_id','grade','ay','num_requests']] \\\n",
    "        .assign( num_requests = lambda _df: _df.num_requests.fillna( 0 ).astype( int ) ) \\\n",
    "        .fillna( '<none>' )\n",
    "    \n",
    "    display(\n",
    "        df\n",
    "            .groupby( [ col for col in df if col != 'num_requests' ] )\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "            .sort_values( [ 'ay', 'grade' ], ascending = [ False, False ] )\n",
    "    )\n",
    "\n",
    "    raise Exception( 'Cannont continue until \"import\" flag is set.' )\n",
    "\n",
    "\n",
    "\n",
    "if mode_school_update == 'import':\n",
    "    school_id_df = pd.read_csv( import_filename )\n",
    "\n",
    "    if len( school_id_df[pd.isnull( school_id_df.school_id_right )] ) > 0:\n",
    "        raise Exception( f'Cannot import school IDs; some schools are still missing IDs.' )\n",
    "    \n",
    "    if len( school_id_df[~pd.isnull( school_id_df.school_id_left ) & ( school_id_df.school_id_left != school_id_df.school_id_right )] ) > 0:\n",
    "        raise Exception( f'Cannot import school IDs; some schools have conflicting IDs.' )\n",
    "    \n",
    "    school_id_df = school_id_df \\\n",
    "        [['school_id_right','school_name']] \\\n",
    "        .rename( columns = { 'school_id_right': 'school_id' } ) \\\n",
    "        .drop_duplicates()\n",
    "    \n",
    "    if len( school_id_df.merge( school_id_df, on = 'school_name' ) ) != len( school_id_df ):\n",
    "        raise Exception( f'Cannot import school IDs; duplicate school names found.' )\n",
    "    \n",
    "    full_df = full_df \\\n",
    "        .merge( school_id_df, on = 'school_name', suffixes = ( '', '_updated' ) ) \\\n",
    "        .assign( school_id = lambda _df: _df.school_id.fillna( _df.school_id_updated ).astype( int ) ) \\\n",
    "        .drop( columns = [ 'school_id_updated' ], axis = 1 ) \\\n",
    "\n",
    "    full_df \\\n",
    "        [['school_id','school_name','ay']] \\\n",
    "        .assign( school_id = lambda _df: _df.school_id.astype( int ) ) \\\n",
    "        .assign( ay_rank = lambda _df: _df[['school_id','ay']].groupby( 'school_id' ).ay.rank( method = 'first', ascending = False ) ) \\\n",
    "        [lambda _df: _df.ay_rank == 1] \\\n",
    "        [['school_id','school_name']] \\\n",
    "        .reset_index( drop = True ) \\\n",
    "        .to_csv( './sfusd-school-id-mapping.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "7cf452b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Massage the program codes\n",
    "#\n",
    "# THIS CELL IS ROUGH. It made more sense to do programmatic overwrites.\n",
    "#\n",
    "modes = [ 'export', 'search', 'import' ]\n",
    "mode_program_update = 'import'\n",
    "\n",
    "search_school_id = 621\n",
    "search_program_name_contains = None\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Some observed programmatic updates\n",
    "#\n",
    "full_df = full_df.assign( program_name = lambda _df: _df.program_name.fillna( '<none>' ) )\n",
    "program_codes = full_df.program_code.unique().tolist()\n",
    "full_df = full_df.assign( program_code = lambda _df: _df.program_name.map( {\n",
    "    'at DeAvila ES Chinese Native Speaker': 'CN', # 19-20 error\n",
    "    'Autism Focus': 'AF', # appears to be the same as MM?\n",
    "    'Cantonese Immersion (Other languages cohort)': 'CT', # this is a guess\n",
    "    'Chinese Biliteracy': 'CB', # formally this has become Cantonese Biliteracy\n",
    "    'Chinese Immersion (Cantonese)': 'CN',\n",
    "    'Chinese Immersion (Non-Native)': 'CE',\n",
    "    'Chinese Immersion (Non-English)': 'CT',\n",
    "    'Chinese Native Speaker': 'CN',\n",
    "    'Chinese Non-Native Speakers': 'CE',\n",
    "    'SDC - Deaf and Hard of Hearing': 'DH',\n",
    "    'Deaf/Hard of Hearing': 'DH',\n",
    "    'DA': 'AO', # this is a guess\n",
    "    'DH': 'DH',\n",
    "    'DT': 'TC', # this is a guess\n",
    "    'Emotionally Disturbed': 'ED',\n",
    "    'Filipino Biliteracy': 'FB',\n",
    "    'Filipino Bilingual': 'FB',\n",
    "    'FIL': 'FB',\n",
    "    'Francisco @ McAteer HS Mild Moderate': 'MM', # this is probably a data issue\n",
    "    'GEN': 'GE',\n",
    "    'Gen Ed': 'GE',\n",
    "    'Gen Ed Newcomer': 'GX',\n",
    "    'General Education': 'GE',\n",
    "    'General Education (SF International only)': 'GX',\n",
    "    'HS Mild Moderate': 'MM',\n",
    "    'Japanese Bilingual': 'JB',\n",
    "    'Japanese Non-Native Cohort': 'JE',\n",
    "    'Japanese Bilingual Bicultural - English': 'JE',\n",
    "    'Japanese Bilingual Bicultural - Japanese': 'JN',\n",
    "    'Japanese Native Cohort': 'JN',\n",
    "    'K-8 Spanish Native': 'SN',\n",
    "    'Korean Immersion (Korean)': 'KN',\n",
    "    'Korean Immersion (Non-Native)': 'KE',\n",
    "    'Korean Native Cohort': 'KN',\n",
    "    'Korean Non-Native Cohort': 'KE',\n",
    "    'Mandarin Immersion (Mandarin)': 'MN',\n",
    "    'Mandarin Immersion (Non-Native)': 'ME',\n",
    "    'Mandarin Native': 'MN',\n",
    "    'Mandarin Non-Native Cohort': 'ME',\n",
    "    'Mild Moderate': 'MM',\n",
    "    'Moderate Severe': 'MS',\n",
    "    'Chinese Newcomer': 'NC',\n",
    "    'NEWC': 'NC',\n",
    "    'Spanish Newcomer': 'NS',\n",
    "    'NEWS': 'NS',\n",
    "    'Newcomer Spanish': 'NS',\n",
    "    'Newcomer': 'NX',\n",
    "    'NEWX': 'NX',\n",
    "    'SDC - Auditory/Oral': 'AO',\n",
    "    'SDC - Social-Emotional/Behavioral Enhanced': 'ED',\n",
    "    'SDC - Social-Emotional/Behavioral\\nEnhanced': 'ED',\n",
    "    'SDC - Severely Autistic': 'SA',\n",
    "    'SDC - Moderate to Severe': 'MS',\n",
    "    'SDC - Mild to Moderate': 'MM',\n",
    "    'SDC - Mild/Mod Autism Focus': 'MM',\n",
    "    'Severely Autistic': 'SA',\n",
    "    'Spanish Biliteracy': 'SB',\n",
    "    'Spanish Bilingual': 'SB', # changed names to biliteracy\n",
    "    'Spanish Immersion (Non-Native)': 'SE',\n",
    "    'Spanish Immersion (Spanish)': 'SN',\n",
    "    'Spanish Non-Native': 'SE',\n",
    "    'Spanish Native': 'SN',\n",
    "    **{ lang: lang for lang in [ 'CHN', 'JPN', 'SPN' ] },\n",
    "    **{ f'IMM{lang[0]}': f'{lang}IMM' for lang in [ 'CHN', 'KOR', 'MND', 'SPN' ] },\n",
    "    **{ code: code for code in program_codes },\n",
    "    **{ f'i{code}': code for code in program_codes }, # this may be an error; pretty sure these are \"i\" for \"integrated\"\n",
    "    **{ f'I{code}': code for code in program_codes } # this may be an error; pretty sure these are \"i\" for \"itegrated\"\n",
    "}).fillna( _df.program_code ))\n",
    "\n",
    "\n",
    "\n",
    "if mode_program_update == 'export':\n",
    "    df = full_df[['ay','school_id','program_code','program_name']].drop_duplicates()\n",
    "    df = df[['school_id','program_code','program_name']][lambda _df: pd.isnull( _df.program_code )].drop_duplicates()\n",
    "    print( len( df ) )\n",
    "    display( df.reset_index().tail( 30 ) )\n",
    "\n",
    "\n",
    "\n",
    "if mode_program_update == 'search':\n",
    "    df = full_df\n",
    "\n",
    "    if search_school_id is not None:\n",
    "        df = df[df.school_id == search_school_id]\n",
    "    if search_program_name_contains is not None:\n",
    "        df = df[df.program_name.fillna( '' ).str.contains( search_program_name_contains )]\n",
    "\n",
    "    df = df[['ay','school_id','program_code','program_name']].drop_duplicates()\n",
    "    display( df.head( 30 ) )\n",
    "    display( df.program_name.drop_duplicates() )\n",
    "\n",
    "\n",
    "\n",
    "if mode_program_update == 'import':\n",
    "    if len( full_df[pd.isnull( full_df.program_code )] ) > 0:\n",
    "        raise Exception( 'Cannot continue: some programs have no program code.' )\n",
    "    \n",
    "    full_df \\\n",
    "        [['ay','school_id','program_code','program_name']] \\\n",
    "        .drop_duplicates() \\\n",
    "        .to_csv( './sfusd-program-code-mapping.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a5d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Save everything\n",
    "#\n",
    "full_df \\\n",
    "    .assign( num_requests = lambda _df: _df.num_requests.fillna( 0 ).apply( lambda x: re.sub( r'(?:\\,|\\.\\d*$)', '', str( x ) ) ) ) \\\n",
    "    .assign( num_requests = lambda _df: np.where( _df.num_requests.str.len() == 0, 0, _df.num_requests.fillna( 0 ) ).astype( int ) ) \\\n",
    "    .drop( [ 'program_name', 'school_name' ], axis = 1 ) \\\n",
    "    .to_csv( './sfusd-lottery-all.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379f948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
